{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5e9670",
   "metadata": {},
   "source": [
    "## 2.routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08abb4",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"../img/flex-logo.png\" width=\"120\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae315a2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <b>your name</b></div>\n",
    "<div style=\"text-align: right\"> Initial issue : 2025.10.02 </div>\n",
    "<div style=\"text-align: right\"> last update : 2025.10.02 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33149ca",
   "metadata": {},
   "source": [
    "개정 이력  \n",
    "- `2025.10.02` : 노트북 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65f19f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3a71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b614b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language model initialized: models/gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760418853.705584 21569429 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "    print(f\"Language model initialized: {llm.model}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing language model: {e}\")\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b114948",
   "metadata": {},
   "source": [
    "1. 가상의 서브 에이전트 핸들러 정의(ADK의 sub_agents 역할)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ab7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def booking_handler(request: str) -> str:\n",
    "    \"\"\"Simulates the Booking Agent handling a request.\"\"\"\n",
    "    print(\"\\n--- 예약 핸들러에게 위임 중 ---\")\n",
    "    return f\"예약 핸들러가 요청을 처리했습니다: '{request}'. 결과: 예약 작업을 시뮬레이션했습니다.\"\n",
    "\n",
    "def info_handler(request: str) -> str:\n",
    "    \"\"\"Simulates the Info Agent handling a request.\"\"\"\n",
    "    print(\"\\n--- 정보 핸들러에게 위임 중 ---\")\n",
    "    return f\"정보 핸들러가 요청을 처리했습니다: '{request}'. 결과: 정보 조회를 시뮬레이션했습니다.\"\n",
    "\n",
    "def unclear_handler(request: str) -> str:\n",
    "    \"\"\"Handles requests that couldn't be delegated.\"\"\"\n",
    "    print(\"\\n--- 불명확한 요청 처리 중 ---\")\n",
    "    return f\"코디네이터가 요청을 위임할 수 없습니다: '{request}'. 내용을 구체적으로 알려주세요.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3de13",
   "metadata": {},
   "source": [
    "2. 라우터 체인 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fde0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator_router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"사용자의 요청을 분석하여 어떤 전문 핸들러가 처리해야 하는지 결정하세요.\n",
    "     - 요청이 항공권 또는 호텔 예약과 관련된 경우,\n",
    "       'booker'를 출력하세요.\n",
    "     - 그 외 일반 정보 질문의 경우 'info'를 출력하세요.\n",
    "     - 요청이 불명확하거나 두 범주에 모두 해당하지 않으면,\n",
    "       'unclear'를 출력하세요.\n",
    "     반드시 한 단어만 출력하세요: 'booker', 'info', 또는 'unclear'.\"\"\"),\n",
    "    (\"user\", \"{request}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7d1660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x12ab5e8d0>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if llm:\n",
    "    coordinator_router_chain = coordinator_router_prompt | llm | StrOutputParser()\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef9a5c",
   "metadata": {},
   "source": [
    "3. Delegation 로직: Runnable 브랜치로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2df40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = {\n",
    "    \"booker\": RunnablePassthrough.assign(output=lambda x: booking_handler(x['request']['request'])),\n",
    "    \"info\": RunnablePassthrough.assign(output=lambda x: info_handler(x['request']['request'])),\n",
    "    \"unclear\": RunnablePassthrough.assign(output=lambda x: unclear_handler(x['request']['request'])),\n",
    "}\n",
    "\n",
    "delegation_branch = RunnableBranch(\n",
    "    (lambda x: x['decision'].strip() == 'booker', branches[\"booker\"]), # Added .strip()\n",
    "    (lambda x: x['decision'].strip() == 'info', branches[\"info\"]),     # Added .strip()\n",
    "    branches[\"unclear\"] # Default branch for 'unclear' or any other output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50768e",
   "metadata": {},
   "source": [
    "4. 라우터 chain과 delegation branch를 조합하여 single runnable 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f442804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The router chain's output ('decision') is passed along with the original input ('request')\n",
    "# to the delegation_branch.\n",
    "coordinator_agent = {\n",
    "    \"decision\": coordinator_router_chain,\n",
    "    \"request\": RunnablePassthrough()\n",
    "} | delegation_branch | (lambda x: x['output']) # Extract the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f198bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running with a booking request ---\n",
      "\n",
      "--- 예약 핸들러에게 위임 중 ---\n",
      "Final Result A: 예약 핸들러가 요청을 처리했습니다: 'Book me a flight to London.'. 결과: 예약 작업을 시뮬레이션했습니다.\n",
      "\n",
      "--- Running with an info request ---\n",
      "\n",
      "--- 정보 핸들러에게 위임 중 ---\n",
      "Final Result B: 정보 핸들러가 요청을 처리했습니다: 'What is the capital of Italy?'. 결과: 정보 조회를 시뮬레이션했습니다.\n",
      "\n",
      "--- Running with an unclear request ---\n",
      "\n",
      "--- 정보 핸들러에게 위임 중 ---\n",
      "Final Result C: 정보 핸들러가 요청을 처리했습니다: 'Tell me about quantum physics.'. 결과: 정보 조회를 시뮬레이션했습니다.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if not llm:\n",
    "        print(\"\\nSkipping execution due to LLM initialization failure.\")\n",
    "        return\n",
    "\n",
    "    print(\"--- Running with a booking request ---\")\n",
    "    request_a = \"Book me a flight to London.\"\n",
    "    result_a = coordinator_agent.invoke({\"request\": request_a})\n",
    "    print(f\"Final Result A: {result_a}\")\n",
    "\n",
    "    print(\"\\n--- Running with an info request ---\")\n",
    "    request_b = \"What is the capital of Italy?\"\n",
    "    result_b = coordinator_agent.invoke({\"request\": request_b})\n",
    "    print(f\"Final Result B: {result_b}\")\n",
    "\n",
    "    print(\"\\n--- Running with an unclear request ---\")\n",
    "    request_c = \"Tell me about quantum physics.\"\n",
    "    result_c = coordinator_agent.invoke({\"request\": request_c})\n",
    "    print(f\"Final Result C: {result_c}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dea349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
